<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Memtable.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Ant Example</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.db</a> &gt; <span class="el_source">Memtable.java</span></div><h1>Memtable.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.db;

import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Throwables;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.cassandra.config.CFMetaData;
import org.apache.cassandra.config.ColumnDefinition;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.config.SchemaConstants;
import org.apache.cassandra.db.commitlog.CommitLog;
import org.apache.cassandra.db.commitlog.CommitLogPosition;
import org.apache.cassandra.db.commitlog.IntervalSet;
import org.apache.cassandra.db.filter.ClusteringIndexFilter;
import org.apache.cassandra.db.filter.ColumnFilter;
import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
import org.apache.cassandra.db.partitions.*;
import org.apache.cassandra.db.rows.EncodingStats;
import org.apache.cassandra.db.rows.UnfilteredRowIterator;
import org.apache.cassandra.dht.*;
import org.apache.cassandra.dht.Murmur3Partitioner.LongToken;
import org.apache.cassandra.index.transactions.UpdateTransaction;
import org.apache.cassandra.io.sstable.Descriptor;
import org.apache.cassandra.io.sstable.SSTableMultiWriter;
import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
import org.apache.cassandra.io.util.FileUtils;
import org.apache.cassandra.service.ActiveRepairService;
import org.apache.cassandra.utils.ByteBufferUtil;
import org.apache.cassandra.utils.FBUtilities;
import org.apache.cassandra.utils.ObjectSizes;
import org.apache.cassandra.utils.concurrent.OpOrder;
import org.apache.cassandra.utils.memory.HeapPool;
import org.apache.cassandra.utils.memory.MemtableAllocator;
import org.apache.cassandra.utils.memory.MemtablePool;
import org.apache.cassandra.utils.memory.NativePool;
import org.apache.cassandra.utils.memory.SlabPool;

<span class="pc bpc" id="L63" title="1 of 2 branches missed.">public class Memtable implements Comparable&lt;Memtable&gt;</span>
{
<span class="fc" id="L65">    private static final Logger logger = LoggerFactory.getLogger(Memtable.class);</span>

<span class="fc" id="L67">    public static final MemtablePool MEMORY_POOL = createMemtableAllocatorPool();</span>

    private static MemtablePool createMemtableAllocatorPool()
    {
<span class="fc" id="L71">        long heapLimit = DatabaseDescriptor.getMemtableHeapSpaceInMb() &lt;&lt; 20;</span>
<span class="fc" id="L72">        long offHeapLimit = DatabaseDescriptor.getMemtableOffheapSpaceInMb() &lt;&lt; 20;</span>
<span class="pc bpc" id="L73" title="4 of 5 branches missed.">        switch (DatabaseDescriptor.getMemtableAllocationType())</span>
        {
            case unslabbed_heap_buffers:
<span class="nc" id="L76">                return new HeapPool(heapLimit, DatabaseDescriptor.getMemtableCleanupThreshold(), new ColumnFamilyStore.FlushLargestColumnFamily());</span>
            case heap_buffers:
<span class="fc" id="L78">                return new SlabPool(heapLimit, 0, DatabaseDescriptor.getMemtableCleanupThreshold(), new ColumnFamilyStore.FlushLargestColumnFamily());</span>
            case offheap_buffers:
<span class="nc bnc" id="L80" title="All 2 branches missed.">                if (!FileUtils.isCleanerAvailable)</span>
                {
<span class="nc" id="L82">                    throw new IllegalStateException(&quot;Could not free direct byte buffer: offheap_buffers is not a safe memtable_allocation_type without this ability, please adjust your config. This feature is only guaranteed to work on an Oracle JVM. Refusing to start.&quot;);</span>
                }
<span class="nc" id="L84">                return new SlabPool(heapLimit, offHeapLimit, DatabaseDescriptor.getMemtableCleanupThreshold(), new ColumnFamilyStore.FlushLargestColumnFamily());</span>
            case offheap_objects:
<span class="nc" id="L86">                return new NativePool(heapLimit, offHeapLimit, DatabaseDescriptor.getMemtableCleanupThreshold(), new ColumnFamilyStore.FlushLargestColumnFamily());</span>
            default:
<span class="nc" id="L88">                throw new AssertionError();</span>
        }
    }

<span class="fc" id="L92">    private static final int ROW_OVERHEAD_HEAP_SIZE = estimateRowOverhead(Integer.parseInt(System.getProperty(&quot;cassandra.memtable_row_overhead_computation_step&quot;, &quot;100000&quot;)));</span>

    private final MemtableAllocator allocator;
<span class="pc" id="L95">    private final AtomicLong liveDataSize = new AtomicLong(0);</span>
<span class="pc" id="L96">    private final AtomicLong currentOperations = new AtomicLong(0);</span>

    // the write barrier for directing writes to this memtable during a switch
    private volatile OpOrder.Barrier writeBarrier;
    // the precise upper bound of CommitLogPosition owned by this memtable
    private volatile AtomicReference&lt;CommitLogPosition&gt; commitLogUpperBound;
    // the precise lower bound of CommitLogPosition owned by this memtable; equal to its predecessor's commitLogUpperBound
    private AtomicReference&lt;CommitLogPosition&gt; commitLogLowerBound;

    // The approximate lower bound by this memtable; must be &lt;= commitLogLowerBound once our predecessor
    // has been finalised, and this is enforced in the ColumnFamilyStore.setCommitLogUpperBound
<span class="pc" id="L107">    private final CommitLogPosition approximateCommitLogLowerBound = CommitLog.instance.getCurrentPosition();</span>

    public int compareTo(Memtable that)
    {
<span class="nc" id="L111">        return this.approximateCommitLogLowerBound.compareTo(that.approximateCommitLogLowerBound);</span>
    }

    public static final class LastCommitLogPosition extends CommitLogPosition
    {
        public LastCommitLogPosition(CommitLogPosition copy)
        {
<span class="fc" id="L118">            super(copy.segmentId, copy.position);</span>
<span class="fc" id="L119">        }</span>
    }

    // We index the memtable by PartitionPosition only for the purpose of being able
    // to select key range using Token.KeyBound. However put() ensures that we
    // actually only store DecoratedKey.
<span class="pc" id="L125">    private final ConcurrentNavigableMap&lt;PartitionPosition, AtomicBTreePartition&gt; partitions = new ConcurrentSkipListMap&lt;&gt;();</span>
    public final ColumnFamilyStore cfs;
<span class="pc" id="L127">    private final long creationNano = System.nanoTime();</span>

    // The smallest timestamp for all partitions stored in this memtable
<span class="pc" id="L130">    private long minTimestamp = Long.MAX_VALUE;</span>

    // Record the comparator of the CFS at the creation of the memtable. This
    // is only used when a user update the CF comparator, to know if the
    // memtable was created with the new or old comparator.
    public final ClusteringComparator initialComparator;

    private final ColumnsCollector columnsCollector;
<span class="pc" id="L138">    private final StatsCollector statsCollector = new StatsCollector();</span>

    // only to be used by init(), to setup the very first memtable for the cfs
    public Memtable(AtomicReference&lt;CommitLogPosition&gt; commitLogLowerBound, ColumnFamilyStore cfs)
<span class="fc" id="L142">    {</span>
<span class="fc" id="L143">        this.cfs = cfs;</span>
<span class="fc" id="L144">        this.commitLogLowerBound = commitLogLowerBound;</span>
<span class="fc" id="L145">        this.allocator = MEMORY_POOL.newAllocator();</span>
<span class="fc" id="L146">        this.initialComparator = cfs.metadata.comparator;</span>
<span class="fc" id="L147">        this.cfs.scheduleFlush();</span>
<span class="fc" id="L148">        this.columnsCollector = new ColumnsCollector(cfs.metadata.partitionColumns());</span>
<span class="fc" id="L149">    }</span>

    // ONLY to be used for testing, to create a mock Memtable
    @VisibleForTesting
    public Memtable(CFMetaData metadata)
<span class="nc" id="L154">    {</span>
<span class="nc" id="L155">        this.initialComparator = metadata.comparator;</span>
<span class="nc" id="L156">        this.cfs = null;</span>
<span class="nc" id="L157">        this.allocator = null;</span>
<span class="nc" id="L158">        this.columnsCollector = new ColumnsCollector(metadata.partitionColumns());</span>
<span class="nc" id="L159">    }</span>

    public MemtableAllocator getAllocator()
    {
<span class="fc" id="L163">        return allocator;</span>
    }

    public long getLiveDataSize()
    {
<span class="nc" id="L168">        return liveDataSize.get();</span>
    }

    public long getOperations()
    {
<span class="fc" id="L173">        return currentOperations.get();</span>
    }

    @VisibleForTesting
    public void setDiscarding(OpOrder.Barrier writeBarrier, AtomicReference&lt;CommitLogPosition&gt; commitLogUpperBound)
    {
<span class="pc bpc" id="L179" title="2 of 4 branches missed.">        assert this.writeBarrier == null;</span>
<span class="fc" id="L180">        this.commitLogUpperBound = commitLogUpperBound;</span>
<span class="fc" id="L181">        this.writeBarrier = writeBarrier;</span>
<span class="fc" id="L182">        allocator.setDiscarding();</span>
<span class="fc" id="L183">    }</span>

    void setDiscarded()
    {
<span class="fc" id="L187">        allocator.setDiscarded();</span>
<span class="fc" id="L188">    }</span>

    // decide if this memtable should take the write, or if it should go to the next memtable
    public boolean accepts(OpOrder.Group opGroup, CommitLogPosition commitLogPosition)
    {
        // if the barrier hasn't been set yet, then this memtable is still taking ALL writes
<span class="fc" id="L194">        OpOrder.Barrier barrier = this.writeBarrier;</span>
<span class="pc bpc" id="L195" title="1 of 2 branches missed.">        if (barrier == null)</span>
<span class="fc" id="L196">            return true;</span>
        // if the barrier has been set, but is in the past, we are definitely destined for a future memtable
<span class="nc bnc" id="L198" title="All 2 branches missed.">        if (!barrier.isAfter(opGroup))</span>
<span class="nc" id="L199">            return false;</span>
        // if we aren't durable we are directed only by the barrier
<span class="nc bnc" id="L201" title="All 2 branches missed.">        if (commitLogPosition == null)</span>
<span class="nc" id="L202">            return true;</span>
        while (true)
        {
            // otherwise we check if we are in the past/future wrt the CL boundary;
            // if the boundary hasn't been finalised yet, we simply update it to the max of
            // its current value and ours; if it HAS been finalised, we simply accept its judgement
            // this permits us to coordinate a safe boundary, as the boundary choice is made
            // atomically wrt our max() maintenance, so an operation cannot sneak into the past
<span class="nc" id="L210">            CommitLogPosition currentLast = commitLogUpperBound.get();</span>
<span class="nc bnc" id="L211" title="All 2 branches missed.">            if (currentLast instanceof LastCommitLogPosition)</span>
<span class="nc bnc" id="L212" title="All 2 branches missed.">                return currentLast.compareTo(commitLogPosition) &gt;= 0;</span>
<span class="nc bnc" id="L213" title="All 4 branches missed.">            if (currentLast != null &amp;&amp; currentLast.compareTo(commitLogPosition) &gt;= 0)</span>
<span class="nc" id="L214">                return true;</span>
<span class="nc bnc" id="L215" title="All 2 branches missed.">            if (commitLogUpperBound.compareAndSet(currentLast, commitLogPosition))</span>
<span class="nc" id="L216">                return true;</span>
<span class="nc" id="L217">        }</span>
    }

    public CommitLogPosition getCommitLogLowerBound()
    {
<span class="fc" id="L222">        return commitLogLowerBound.get();</span>
    }

    public CommitLogPosition getCommitLogUpperBound()
    {
<span class="fc" id="L227">        return commitLogUpperBound.get();</span>
    }

    public boolean isLive()
    {
<span class="nc" id="L232">        return allocator.isLive();</span>
    }

    public boolean isClean()
    {
<span class="fc" id="L237">        return partitions.isEmpty();</span>
    }

    public boolean mayContainDataBefore(CommitLogPosition position)
    {
<span class="nc bnc" id="L242" title="All 2 branches missed.">        return approximateCommitLogLowerBound.compareTo(position) &lt; 0;</span>
    }

    /**
     * @return true if this memtable is expired. Expiration time is determined by CF's memtable_flush_period_in_ms.
     */
    public boolean isExpired()
    {
<span class="nc" id="L250">        int period = cfs.metadata.params.memtableFlushPeriodInMs;</span>
<span class="nc bnc" id="L251" title="All 4 branches missed.">        return period &gt; 0 &amp;&amp; (System.nanoTime() - creationNano &gt;= TimeUnit.MILLISECONDS.toNanos(period));</span>
    }

    /**
     * Should only be called by ColumnFamilyStore.apply via Keyspace.apply, which supplies the appropriate
     * OpOrdering.
     *
     * commitLogSegmentPosition should only be null if this is a secondary index, in which case it is *expected* to be null
     */
    long put(PartitionUpdate update, UpdateTransaction indexer, OpOrder.Group opGroup)
    {
<span class="fc" id="L262">        AtomicBTreePartition previous = partitions.get(update.partitionKey());</span>

<span class="fc" id="L264">        long initialSize = 0;</span>
<span class="fc bfc" id="L265" title="All 2 branches covered.">        if (previous == null)</span>
        {
<span class="fc" id="L267">            final DecoratedKey cloneKey = allocator.clone(update.partitionKey(), opGroup);</span>
<span class="fc" id="L268">            AtomicBTreePartition empty = new AtomicBTreePartition(cfs.metadata, cloneKey, allocator);</span>
            // We'll add the columns later. This avoids wasting works if we get beaten in the putIfAbsent
<span class="fc" id="L270">            previous = partitions.putIfAbsent(cloneKey, empty);</span>
<span class="fc bfc" id="L271" title="All 2 branches covered.">            if (previous == null)</span>
            {
<span class="fc" id="L273">                previous = empty;</span>
                // allocate the row overhead after the fact; this saves over allocating and having to free after, but
                // means we can overshoot our declared limit.
<span class="fc" id="L276">                int overhead = (int) (cloneKey.getToken().getHeapSize() + ROW_OVERHEAD_HEAP_SIZE);</span>
<span class="fc" id="L277">                allocator.onHeap().allocate(overhead, opGroup);</span>
<span class="fc" id="L278">                initialSize = 8;</span>
            }
        }

<span class="fc" id="L282">        long[] pair = previous.addAllWithSizeDelta(update, opGroup, indexer);</span>
<span class="fc" id="L283">        minTimestamp = Math.min(minTimestamp, previous.stats().minTimestamp);</span>
<span class="fc" id="L284">        liveDataSize.addAndGet(initialSize + pair[0]);</span>
<span class="fc" id="L285">        columnsCollector.update(update.columns());</span>
<span class="fc" id="L286">        statsCollector.update(update.stats());</span>
<span class="fc" id="L287">        currentOperations.addAndGet(update.operationCount());</span>
<span class="fc" id="L288">        return pair[1];</span>
    }

    public int partitionCount()
    {
<span class="nc" id="L293">        return partitions.size();</span>
    }

    public List&lt;FlushRunnable&gt; flushRunnables(LifecycleTransaction txn)
    {
<span class="fc" id="L298">        return createFlushRunnables(txn);</span>
    }

    private List&lt;FlushRunnable&gt; createFlushRunnables(LifecycleTransaction txn)
    {
<span class="fc" id="L303">        DiskBoundaries diskBoundaries = cfs.getDiskBoundaries();</span>
<span class="fc" id="L304">        List&lt;PartitionPosition&gt; boundaries = diskBoundaries.positions;</span>
<span class="fc" id="L305">        List&lt;Directories.DataDirectory&gt; locations = diskBoundaries.directories;</span>
<span class="pc bpc" id="L306" title="1 of 2 branches missed.">        if (boundaries == null)</span>
<span class="fc" id="L307">            return Collections.singletonList(new FlushRunnable(txn));</span>

<span class="nc" id="L309">        List&lt;FlushRunnable&gt; runnables = new ArrayList&lt;&gt;(boundaries.size());</span>
<span class="nc" id="L310">        PartitionPosition rangeStart = cfs.getPartitioner().getMinimumToken().minKeyBound();</span>
        try
        {
<span class="nc bnc" id="L313" title="All 2 branches missed.">            for (int i = 0; i &lt; boundaries.size(); i++)</span>
            {
<span class="nc" id="L315">                PartitionPosition t = boundaries.get(i);</span>
<span class="nc" id="L316">                runnables.add(new FlushRunnable(rangeStart, t, locations.get(i), txn));</span>
<span class="nc" id="L317">                rangeStart = t;</span>
            }
<span class="nc" id="L319">            return runnables;</span>
        }
<span class="nc" id="L321">        catch (Throwable e)</span>
        {
<span class="nc" id="L323">            throw Throwables.propagate(abortRunnables(runnables, e));</span>
        }
    }

    public Throwable abortRunnables(List&lt;FlushRunnable&gt; runnables, Throwable t)
    {
<span class="nc bnc" id="L329" title="All 2 branches missed.">        if (runnables != null)</span>
<span class="nc bnc" id="L330" title="All 2 branches missed.">            for (FlushRunnable runnable : runnables)</span>
<span class="nc" id="L331">                t = runnable.writer.abort(t);</span>
<span class="nc" id="L332">        return t;</span>
    }

    public String toString()
    {
<span class="fc" id="L337">        return String.format(&quot;Memtable-%s@%s(%s serialized bytes, %s ops, %.0f%%/%.0f%% of on/off-heap limit)&quot;,</span>
<span class="fc" id="L338">                             cfs.name, hashCode(), FBUtilities.prettyPrintMemory(liveDataSize.get()), currentOperations,</span>
<span class="fc" id="L339">                             100 * allocator.onHeap().ownershipRatio(), 100 * allocator.offHeap().ownershipRatio());</span>
    }

    public MemtableUnfilteredPartitionIterator makePartitionIterator(final ColumnFilter columnFilter, final DataRange dataRange, final boolean isForThrift)
    {
<span class="fc" id="L344">        AbstractBounds&lt;PartitionPosition&gt; keyRange = dataRange.keyRange();</span>

<span class="fc" id="L346">        boolean startIsMin = keyRange.left.isMinimum();</span>
<span class="fc" id="L347">        boolean stopIsMin = keyRange.right.isMinimum();</span>

<span class="fc" id="L349">        boolean isBound = keyRange instanceof Bounds;</span>
<span class="pc bpc" id="L350" title="2 of 4 branches missed.">        boolean includeStart = isBound || keyRange instanceof IncludingExcludingBounds;</span>
<span class="pc bpc" id="L351" title="1 of 4 branches missed.">        boolean includeStop = isBound || keyRange instanceof Range;</span>
        Map&lt;PartitionPosition, AtomicBTreePartition&gt; subMap;
<span class="fc bfc" id="L353" title="All 2 branches covered.">        if (startIsMin)</span>
<span class="fc bfc" id="L354" title="All 2 branches covered.">            subMap = stopIsMin ? partitions : partitions.headMap(keyRange.right, includeStop);</span>
        else
<span class="fc bfc" id="L356" title="All 2 branches covered.">            subMap = stopIsMin</span>
<span class="fc" id="L357">                   ? partitions.tailMap(keyRange.left, includeStart)</span>
<span class="fc" id="L358">                   : partitions.subMap(keyRange.left, includeStart, keyRange.right, includeStop);</span>

<span class="fc" id="L360">        int minLocalDeletionTime = Integer.MAX_VALUE;</span>

        // avoid iterating over the memtable if we purge all tombstones
<span class="pc bpc" id="L363" title="1 of 2 branches missed.">        if (cfs.getCompactionStrategyManager().onlyPurgeRepairedTombstones())</span>
<span class="nc" id="L364">            minLocalDeletionTime = findMinLocalDeletionTime(subMap.entrySet().iterator());</span>

<span class="fc" id="L366">        final Iterator&lt;Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt;&gt; iter = subMap.entrySet().iterator();</span>

<span class="fc" id="L368">        return new MemtableUnfilteredPartitionIterator(cfs, iter, isForThrift, minLocalDeletionTime, columnFilter, dataRange);</span>
    }

    private int findMinLocalDeletionTime(Iterator&lt;Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt;&gt; iterator)
    {
<span class="nc" id="L373">        int minLocalDeletionTime = Integer.MAX_VALUE;</span>
<span class="nc bnc" id="L374" title="All 2 branches missed.">        while (iterator.hasNext())</span>
        {
<span class="nc" id="L376">            Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt; entry = iterator.next();</span>
<span class="nc" id="L377">            minLocalDeletionTime = Math.min(minLocalDeletionTime, entry.getValue().stats().minLocalDeletionTime);</span>
<span class="nc" id="L378">        }</span>
<span class="nc" id="L379">        return minLocalDeletionTime;</span>
    }

    public Partition getPartition(DecoratedKey key)
    {
<span class="fc" id="L384">        return partitions.get(key);</span>
    }

    public long getMinTimestamp()
    {
<span class="fc" id="L389">        return minTimestamp;</span>
    }

    /**
     * For testing only. Give this memtable too big a size to make it always fail flushing.
     */
    @VisibleForTesting
    public void makeUnflushable()
    {
<span class="nc" id="L398">        liveDataSize.addAndGet(1L * 1024 * 1024 * 1024 * 1024 * 1024);</span>
<span class="nc" id="L399">    }</span>

<span class="pc bpc" id="L401" title="1 of 2 branches missed.">    class FlushRunnable implements Callable&lt;SSTableMultiWriter&gt;</span>
    {
        private final long estimatedSize;
        private final ConcurrentNavigableMap&lt;PartitionPosition, AtomicBTreePartition&gt; toFlush;

        private final boolean isBatchLogTable;
        private final SSTableMultiWriter writer;

        // keeping these to be able to log what we are actually flushing
        private final PartitionPosition from;
        private final PartitionPosition to;

        FlushRunnable(PartitionPosition from, PartitionPosition to, Directories.DataDirectory flushLocation, LifecycleTransaction txn)
        {
<span class="nc" id="L415">            this(partitions.subMap(from, to), flushLocation, from, to, txn);</span>
<span class="nc" id="L416">        }</span>

        FlushRunnable(LifecycleTransaction txn)
        {
<span class="fc" id="L420">            this(partitions, null, null, null, txn);</span>
<span class="fc" id="L421">        }</span>

        FlushRunnable(ConcurrentNavigableMap&lt;PartitionPosition, AtomicBTreePartition&gt; toFlush, Directories.DataDirectory flushLocation, PartitionPosition from, PartitionPosition to, LifecycleTransaction txn)
<span class="fc" id="L424">        {</span>
<span class="fc" id="L425">            this.toFlush = toFlush;</span>
<span class="fc" id="L426">            this.from = from;</span>
<span class="fc" id="L427">            this.to = to;</span>
<span class="fc" id="L428">            long keySize = 0;</span>
<span class="fc bfc" id="L429" title="All 2 branches covered.">            for (PartitionPosition key : toFlush.keySet())</span>
            {
                //  make sure we don't write non-sensical keys
<span class="pc bpc" id="L432" title="2 of 4 branches missed.">                assert key instanceof DecoratedKey;</span>
<span class="fc" id="L433">                keySize += ((DecoratedKey) key).getKey().remaining();</span>
<span class="fc" id="L434">            }</span>
<span class="fc" id="L435">            estimatedSize = (long) ((keySize // index entries</span>
                                    + keySize // keys in data file
<span class="fc" id="L437">                                    + liveDataSize.get()) // data</span>
                                    * 1.2); // bloom filter and row index overhead

<span class="pc bpc" id="L440" title="3 of 4 branches missed.">            this.isBatchLogTable = cfs.name.equals(SystemKeyspace.BATCHES) &amp;&amp; cfs.keyspace.getName().equals(SchemaConstants.SYSTEM_KEYSPACE_NAME);</span>

<span class="pc bpc" id="L442" title="1 of 2 branches missed.">            if (flushLocation == null)</span>
<span class="fc" id="L443">                writer = createFlushWriter(txn, cfs.getSSTablePath(getDirectories().getWriteableLocationAsFile(estimatedSize)), columnsCollector.get(), statsCollector.get());</span>
            else
<span class="nc" id="L445">                writer = createFlushWriter(txn, cfs.getSSTablePath(getDirectories().getLocationForDisk(flushLocation)), columnsCollector.get(), statsCollector.get());</span>

<span class="fc" id="L447">        }</span>

        protected Directories getDirectories()
        {
<span class="fc" id="L451">            return cfs.getDirectories();</span>
        }

        private void writeSortedContents()
        {
<span class="fc" id="L456">            logger.debug(&quot;Writing {}, flushed range = ({}, {}]&quot;, Memtable.this.toString(), from, to);</span>

<span class="fc" id="L458">            boolean trackContention = logger.isTraceEnabled();</span>
<span class="fc" id="L459">            int heavilyContendedRowCount = 0;</span>
            // (we can't clear out the map as-we-go to free up memory,
            //  since the memtable is being used for queries in the &quot;pending flush&quot; category)
<span class="fc bfc" id="L462" title="All 2 branches covered.">            for (AtomicBTreePartition partition : toFlush.values())</span>
            {
                // Each batchlog partition is a separate entry in the log. And for an entry, we only do 2
                // operations: 1) we insert the entry and 2) we delete it. Further, BL data is strictly local,
                // we don't need to preserve tombstones for repair. So if both operation are in this
                // memtable (which will almost always be the case if there is no ongoing failure), we can
                // just skip the entry (CASSANDRA-4667).
<span class="pc bpc" id="L469" title="5 of 6 branches missed.">                if (isBatchLogTable &amp;&amp; !partition.partitionLevelDeletion().isLive() &amp;&amp; partition.hasRows())</span>
<span class="nc" id="L470">                    continue;</span>

<span class="pc bpc" id="L472" title="3 of 4 branches missed.">                if (trackContention &amp;&amp; partition.usePessimisticLocking())</span>
<span class="nc" id="L473">                    heavilyContendedRowCount++;</span>

<span class="pc bpc" id="L475" title="1 of 2 branches missed.">                if (!partition.isEmpty())</span>
                {
<span class="fc" id="L477">                    try (UnfilteredRowIterator iter = partition.unfilteredIterator())</span>
                    {
<span class="fc" id="L479">                        writer.append(iter);</span>
                    }
                }
<span class="fc" id="L482">            }</span>

<span class="fc" id="L484">            long bytesFlushed = writer.getFilePointer();</span>
<span class="fc" id="L485">            logger.debug(&quot;Completed flushing {} ({}) for commitlog position {}&quot;,</span>
<span class="fc" id="L486">                                                                              writer.getFilename(),</span>
<span class="fc" id="L487">                                                                              FBUtilities.prettyPrintMemory(bytesFlushed),</span>
<span class="fc" id="L488">                                                                              commitLogUpperBound);</span>
            // Update the metrics
<span class="fc" id="L490">            cfs.metric.bytesFlushed.inc(bytesFlushed);</span>

<span class="pc bpc" id="L492" title="1 of 2 branches missed.">            if (heavilyContendedRowCount &gt; 0)</span>
<span class="nc" id="L493">                logger.trace(&quot;High update contention in {}/{} partitions of {} &quot;, heavilyContendedRowCount, toFlush.size(), Memtable.this);</span>
<span class="fc" id="L494">        }</span>

        public SSTableMultiWriter createFlushWriter(LifecycleTransaction txn,
                                                  String filename,
                                                  PartitionColumns columns,
                                                  EncodingStats stats)
        {
<span class="fc" id="L501">            MetadataCollector sstableMetadataCollector = new MetadataCollector(cfs.metadata.comparator)</span>
<span class="fc" id="L502">                    .commitLogIntervals(new IntervalSet&lt;&gt;(commitLogLowerBound.get(), commitLogUpperBound.get()));</span>

<span class="fc" id="L504">            return cfs.createSSTableMultiWriter(Descriptor.fromFilename(filename),</span>
<span class="fc" id="L505">                                                toFlush.size(),</span>
                                                ActiveRepairService.UNREPAIRED_SSTABLE,
                                                sstableMetadataCollector,
                                                new SerializationHeader(true, cfs.metadata, columns, stats), txn);
        }

        @Override
        public SSTableMultiWriter call()
        {
<span class="fc" id="L514">            writeSortedContents();</span>
<span class="fc" id="L515">            return writer;</span>
        }
    }

    private static int estimateRowOverhead(final int count)
    {
        // calculate row overhead
<span class="fc" id="L522">        try (final OpOrder.Group group = new OpOrder().start())</span>
        {
            int rowOverhead;
<span class="fc" id="L525">            MemtableAllocator allocator = MEMORY_POOL.newAllocator();</span>
<span class="fc" id="L526">            ConcurrentNavigableMap&lt;PartitionPosition, Object&gt; partitions = new ConcurrentSkipListMap&lt;&gt;();</span>
<span class="fc" id="L527">            final Object val = new Object();</span>
<span class="fc bfc" id="L528" title="All 2 branches covered.">            for (int i = 0 ; i &lt; count ; i++)</span>
<span class="fc" id="L529">                partitions.put(allocator.clone(new BufferDecoratedKey(new LongToken(i), ByteBufferUtil.EMPTY_BYTE_BUFFER), group), val);</span>
<span class="fc" id="L530">            double avgSize = ObjectSizes.measureDeep(partitions) / (double) count;</span>
<span class="pc bpc" id="L531" title="1 of 2 branches missed.">            rowOverhead = (int) ((avgSize - Math.floor(avgSize)) &lt; 0.05 ? Math.floor(avgSize) : Math.ceil(avgSize));</span>
<span class="fc" id="L532">            rowOverhead -= ObjectSizes.measureDeep(new LongToken(0));</span>
<span class="fc" id="L533">            rowOverhead += AtomicBTreePartition.EMPTY_SIZE;</span>
<span class="fc" id="L534">            allocator.setDiscarding();</span>
<span class="fc" id="L535">            allocator.setDiscarded();</span>
<span class="fc" id="L536">            return rowOverhead;</span>
        }
    }

<span class="pc bpc" id="L540" title="1 of 2 branches missed.">    public static class MemtableUnfilteredPartitionIterator extends AbstractUnfilteredPartitionIterator</span>
    {
        private final ColumnFamilyStore cfs;
        private final Iterator&lt;Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt;&gt; iter;
        private final boolean isForThrift;
        private final int minLocalDeletionTime;
        private final ColumnFilter columnFilter;
        private final DataRange dataRange;

        public MemtableUnfilteredPartitionIterator(ColumnFamilyStore cfs, Iterator&lt;Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt;&gt; iter, boolean isForThrift, int minLocalDeletionTime, ColumnFilter columnFilter, DataRange dataRange)
<span class="fc" id="L550">        {</span>
<span class="fc" id="L551">            this.cfs = cfs;</span>
<span class="fc" id="L552">            this.iter = iter;</span>
<span class="fc" id="L553">            this.isForThrift = isForThrift;</span>
<span class="fc" id="L554">            this.minLocalDeletionTime = minLocalDeletionTime;</span>
<span class="fc" id="L555">            this.columnFilter = columnFilter;</span>
<span class="fc" id="L556">            this.dataRange = dataRange;</span>
<span class="fc" id="L557">        }</span>

        public boolean isForThrift()
        {
<span class="fc" id="L561">            return isForThrift;</span>
        }

        public int getMinLocalDeletionTime()
        {
<span class="fc" id="L566">            return minLocalDeletionTime;</span>
        }

        public CFMetaData metadata()
        {
<span class="fc" id="L571">            return cfs.metadata;</span>
        }

        public boolean hasNext()
        {
<span class="fc" id="L576">            return iter.hasNext();</span>
        }

        public UnfilteredRowIterator next()
        {
<span class="fc" id="L581">            Map.Entry&lt;PartitionPosition, AtomicBTreePartition&gt; entry = iter.next();</span>
            // Actual stored key should be true DecoratedKey
<span class="pc bpc" id="L583" title="2 of 4 branches missed.">            assert entry.getKey() instanceof DecoratedKey;</span>
<span class="fc" id="L584">            DecoratedKey key = (DecoratedKey)entry.getKey();</span>
<span class="fc" id="L585">            ClusteringIndexFilter filter = dataRange.clusteringIndexFilter(key);</span>

<span class="fc" id="L587">            return filter.getUnfilteredRowIterator(columnFilter, entry.getValue());</span>
        }
    }

    private static class ColumnsCollector
    {
<span class="fc" id="L593">        private final HashMap&lt;ColumnDefinition, AtomicBoolean&gt; predefined = new HashMap&lt;&gt;();</span>
<span class="fc" id="L594">        private final ConcurrentSkipListSet&lt;ColumnDefinition&gt; extra = new ConcurrentSkipListSet&lt;&gt;();</span>
        ColumnsCollector(PartitionColumns columns)
<span class="fc" id="L596">        {</span>
<span class="fc bfc" id="L597" title="All 2 branches covered.">            for (ColumnDefinition def : columns.statics)</span>
<span class="fc" id="L598">                predefined.put(def, new AtomicBoolean());</span>
<span class="fc bfc" id="L599" title="All 2 branches covered.">            for (ColumnDefinition def : columns.regulars)</span>
<span class="fc" id="L600">                predefined.put(def, new AtomicBoolean());</span>
<span class="fc" id="L601">        }</span>

        public void update(PartitionColumns columns)
        {
<span class="pc bpc" id="L605" title="1 of 2 branches missed.">            for (ColumnDefinition s : columns.statics)</span>
<span class="nc" id="L606">                update(s);</span>
<span class="fc bfc" id="L607" title="All 2 branches covered.">            for (ColumnDefinition r : columns.regulars)</span>
<span class="fc" id="L608">                update(r);</span>
<span class="fc" id="L609">        }</span>

        private void update(ColumnDefinition definition)
        {
<span class="fc" id="L613">            AtomicBoolean present = predefined.get(definition);</span>
<span class="pc bpc" id="L614" title="1 of 2 branches missed.">            if (present != null)</span>
            {
<span class="fc bfc" id="L616" title="All 2 branches covered.">                if (!present.get())</span>
<span class="fc" id="L617">                    present.set(true);</span>
            }
            else
            {
<span class="nc" id="L621">                extra.add(definition);</span>
            }
<span class="fc" id="L623">        }</span>

        public PartitionColumns get()
        {
<span class="fc" id="L627">            PartitionColumns.Builder builder = PartitionColumns.builder();</span>
<span class="fc bfc" id="L628" title="All 2 branches covered.">            for (Map.Entry&lt;ColumnDefinition, AtomicBoolean&gt; e : predefined.entrySet())</span>
<span class="fc bfc" id="L629" title="All 2 branches covered.">                if (e.getValue().get())</span>
<span class="fc" id="L630">                    builder.add(e.getKey());</span>
<span class="fc" id="L631">            return builder.addAll(extra).build();</span>
        }
    }

<span class="fc" id="L635">    private static class StatsCollector</span>
    {
<span class="fc" id="L637">        private final AtomicReference&lt;EncodingStats&gt; stats = new AtomicReference&lt;&gt;(EncodingStats.NO_STATS);</span>

        public void update(EncodingStats newStats)
        {
            while (true)
            {
<span class="fc" id="L643">                EncodingStats current = stats.get();</span>
<span class="fc" id="L644">                EncodingStats updated = current.mergeWith(newStats);</span>
<span class="pc bpc" id="L645" title="1 of 2 branches missed.">                if (stats.compareAndSet(current, updated))</span>
<span class="fc" id="L646">                    return;</span>
<span class="nc" id="L647">            }</span>
        }

        public EncodingStats get()
        {
<span class="fc" id="L652">            return stats.get();</span>
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>